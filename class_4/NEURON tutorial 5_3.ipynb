{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Putting things together 3\n",
    "\n",
    "Here we will define a cell model with multiple sections and create a network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training of network models\n",
    "\n",
    "- Artificial neural network models are optimized to generate ideal behavior, \n",
    "    - E.g., replication of data with the smallest error possible. \n",
    "- Those optimization, or training methods are rarely related to mechanisms in the biological neural circuits.\n",
    "- But what would happen if we optimize the models of biological neural networks by those artificial methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](imgs/zipster_1.png)\n",
    "\n",
    "- They trained the three-layer neural network model of the visual pathway by backpropagation, which replicated their experimental data from the visual cortical neurons.\n",
    "- This is hardly biological since no backpropagation is possible from the visual cortex to retina.\n",
    "- ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](imgs/zipster_2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimizing the network model\n",
    "\n",
    "Optimizing a network model of spiking neurons is still a very difficult problem. Here, we use an approach by [Nicola and Clopath, Nat Commun, 2017](https://www.nature.com/articles/s41467-017-01827-3), which works relatively well.\n",
    "\n",
    "The basic idea is\n",
    "1. Find a linear decoder to fit the data by a linear combination of neuronal activity.\n",
    "$$ z = {\\bf \\phi}\\cdot {\\bf r}$$\n",
    "where $r_i$ is the 'rate' of the neuron $i$, computed by integrating the spikes with a time window, just like synaptic conductance.\n",
    "2. Inject $z$ as a modulating input to neurons with some random weight ${\\bf \\eta}$,\n",
    "$$ C\\frac{dV_i}{dt} = \\text{intrinsic current} + \\text{network inputs} + \\eta_i z$$\n",
    "3. If we rewite the equation\n",
    "$$ C\\frac{dV_i}{dt} = \\text{intrinsic current} + \\text{network inputs} + \\sum_{j}\\eta_i \\phi_j r_j$$\n",
    "Note that the last term can be interpreted as modifying the network connectivity since $r_j$ can be thought as the synaptic conductance triggered by spike inputs from neuron $j$.\n",
    "4. Now go back to step 1 and repeat the loop until converges.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plan\n",
    "\n",
    "1. We will first run the simulation for a short time period,\n",
    "2. Just as Nicola and Clopath, we will use the recursive least square (RLS) method to find $\\bf \\phi$.\n",
    "3. We modify the connectivity accordingly by $\\bf \\phi$.\n",
    "4. We will repeat the steps and hope that it converges!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Network is all-to-all connected where the weights are from Gaussian random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import trange\n",
    "\n",
    "Ncells= 1000\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for i in range(Ncells):\n",
    "    G.add_node(i)\n",
    "\n",
    "for i in G.nodes:\n",
    "\n",
    "    exc_pre = np.arange(0, Ncells)\n",
    "    for k in G.nodes:\n",
    "        if i!=k:  # No self-connection\n",
    "            if k in exc_pre:\n",
    "                G.add_edge(i, k, weight=np.random.randn())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We first create neurons in the network according to the plan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron import h, gui, load_mechanisms\n",
    "from net_manager import SerialNetManager\n",
    "from cell_models import Mainen, Mease\n",
    "\n",
    "pnm = SerialNetManager(len(G.nodes))\n",
    "\n",
    "for i in G.nodes:\n",
    "    # pnm.register_cell(i, Mease(i))\n",
    "    pnm.register_cell(i, Mainen(i, rho=80, c=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Then, we add brief stimuli for the cells to kickstart the network activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kickstart stims\n",
    "ext_stims = []\n",
    "ext_ncs = []\n",
    "for i in G.nodes:\n",
    "    stim = h.NetStimFD(pnm.gid2cell[i].soma(0.5))\n",
    "    stim.interval = 4\n",
    "    stim.noise = 1\n",
    "    stim.start = 0\n",
    "    stim.duration = 2\n",
    "    stim.seed(i+1223)\n",
    "\n",
    "    nc = h.NetCon(stim, pnm.gid2cell[i].synlist[1])\n",
    "    nc.weight[0] = 6e-4\n",
    "    ext_stims.append((stim, nc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnm.want_all_spikes()\n",
    "\n",
    "h.tstop = 400\n",
    "h.init()\n",
    "pnm.run()\n",
    "\n",
    "Ncells = len(G.nodes)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.plot(pnm.spikevec, pnm.idvec, '.k')\n",
    "ax.set(xlim=[0, 200], ylim=[0, Ncells])\n",
    "ax.set(xlabel='Time (ms)', ylabel='Neuron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Then we wire the cells for each edge in our plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gexc = 1e-8     # initial value --- will be adjusted later\n",
    "\n",
    "# Reset all NetCon's\n",
    "pnm.nc_reset()\n",
    "\n",
    "# Go around every cell\n",
    "for i in G.nodes:\n",
    "    for k in G[i]:\n",
    "        t_delay = np.random.rand()*0.01\n",
    "        g = gexc*G[i][k]['weight']\n",
    "        # pnm.nc_append(k, i, 0, g, t_delay, thresh=-10)\n",
    "        pnm.nc_append(k, i, 1, g, t_delay, thresh=-10)\n",
    "        # pnm.nc_append(k, i, 1, g, t_delay, thresh=-10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_global_synaptic_conductance(gexc, G, pnm):\n",
    "    \"\"\"adjuct synaptic conductances all around the network\"\"\"\n",
    "\n",
    "    for nc in pnm.netcons:\n",
    "        k, i, _ = nc\n",
    "        g = gexc*G[i][k]['weight']\n",
    "        pnm.netcons[nc].weight[0] = g\n",
    "\n",
    "        \n",
    "def repack_result(pnm, G, t_init=75):\n",
    "    \"\"\"pack the simulation results into a matrix\"\"\"\n",
    "    x = np.array([pnm.spikevec, pnm.idvec]).T\n",
    "    x = x[x[:,0]>t_init,:]\n",
    "    x[:,0] -= t_init\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pnm.want_all_spikes() #will record spikes from all the neurons\n",
    "    \n",
    "set_global_synaptic_conductance(1.8e-4, G, pnm)\n",
    "h.v_init = -70\n",
    "t_init = 150\n",
    "\n",
    "h.tstop = t_init+70\n",
    "h.init()\n",
    "pnm.run()\n",
    "\n",
    "x = repack_result(pnm, G, t_init=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.scatter(x[:,0], x[:,1], 2)\n",
    "ax.set(xlabel='Time (ms)', ylabel='Neuron', xlim=[0, h.tstop-75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's begin! Let's run the network for a while to stabilize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnm.want_all_spikes()\n",
    "\n",
    "gexc = 1.8e-4\n",
    "t_init = 300\n",
    "\n",
    "set_global_synaptic_conductance(gexc, G, pnm)\n",
    "\n",
    "h.tstop = t_init\n",
    "h.init()\n",
    "pnm.run()\n",
    "\n",
    "x = repack_result(pnm, G, t_init=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.scatter(x[:,0], x[:,1], 2)\n",
    "ax.set(xlabel='Time (ms)', ylabel='Neuron', xlim=[0, h.tstop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Here we define some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target function\n",
    "fref = lambda t: np.sin(2*np.pi*t/500) \n",
    "\n",
    "# Initial phi\n",
    "phi = np.zeros(Ncells)\n",
    "# A matrix that we need for the RLS method\n",
    "P = np.eye(Ncells)\n",
    "\n",
    "# Coefficients from two network inputs\n",
    "G = 1\n",
    "Q = 1\n",
    "\n",
    "# Random feedback to neurons\n",
    "eta = np.random.uniform(low=-1.0, high=1.0, size=Ncells)\n",
    "\n",
    "# Batch period length for each iteration\n",
    "t_batch = 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# we will store computed rates of individual cells in this matrix\n",
    "r = np.zeros((Ncells, t_batch))\n",
    "\n",
    "# The integration parameter, roughly the same as synapses in this model\n",
    "dt = 1.0\n",
    "tau = 20.0\n",
    "\n",
    "# A list to collect all the data\n",
    "x_before_after = []\n",
    "\n",
    "#Batch count\n",
    "cbatch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's run a few batches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# pnm.want_all_spikes()\n",
    "for i_batch in trange(cbatch, cbatch+10, 1):\n",
    "\n",
    "    # When the batch starts\n",
    "    t_batch_start = t_init + (i_batch)*t_batch\n",
    "\n",
    "    # For every netcons ...\n",
    "    for nc in pnm.netcons:\n",
    "        # for connecting i -> k\n",
    "        k, i, _ = nc\n",
    "        \n",
    "        # synaptic weight is determined by the original + feedback from phi\n",
    "        g = gexc*(G[i][k]['weight']*G + eta[i]*phi[k]*Q)\n",
    "        pnm.netcons[nc].weight[0] = g\n",
    "\n",
    "    \n",
    "    # Run the simulation briefly\n",
    "    pnm.continuerun(t_batch_start + t_batch)\n",
    "\n",
    "\n",
    "    # Collect the spike data\n",
    "    x = repack_result(pnm, G, t_init=t_batch_start)\n",
    "\n",
    "    # Transform the spikes into a matrix (Ncells, t_batch)\n",
    "    s_all = np.zeros((Ncells, t_batch), dtype='float')\n",
    "    x = x[x[:,0]<=t_batch,:]\n",
    "    s_all[x[:,1].astype(int), x[:,0].astype(int)] = 1\n",
    "    s = s_all[:,:]\n",
    "\n",
    "    # Turn it into a rate\n",
    "    for i in range(s.shape[1]):\n",
    "        if i==0:\n",
    "            r_prev = r[:,-1]\n",
    "        else:\n",
    "            r_prev = r[:, i-1]\n",
    "        r[:,i] = (r_prev + s[:,i]*dt)/(1+dt/tau)\n",
    "\n",
    "    # Collect the data before optimization\n",
    "    tt = np.arange(t_batch) + t_batch_start\n",
    "    x_before_after.append([tt, r.mean(axis=0), fref(tt), np.matmul(phi, r)])\n",
    "\n",
    "\n",
    "    # RLS: See Nicola and Clopath for the details\n",
    "    for t in range(t_batch):\n",
    "        Pr = np.matmul(P, r[:,t])\n",
    "        PrrP = np.matmul(Pr[:,np.newaxis], Pr[np.newaxis,:])\n",
    "        rPr = np.matmul(r[:,t], Pr)\n",
    "        P = P - PrrP/(1 + rPr)\n",
    "\n",
    "        Pr = np.matmul(P, r[:,t])\n",
    "\n",
    "        err = np.matmul(phi, r[:,t]) - fref(t+t_batch_start)\n",
    "        phi = phi - err*Pr\n",
    "\n",
    "    # Store the final result\n",
    "    x_before_after[-1].append(np.matmul(phi, r))\n",
    "    \n",
    "cbatch = i_batch+1\n",
    "print(f'Next batch starts at batch = {cbatch}'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's check the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(20,5))\n",
    "\n",
    "for t, _, xt, xhb, xha in x_before_after:\n",
    "    # ax.plot(t, 10*(rmean-rmean.mean()), 'c')\n",
    "    ax.plot(t, xha,':g')\n",
    "    ax.plot(t, xhb,'r')\n",
    "    ax.plot(t, xt,'-k')\n",
    "    ax.set_title(i_batch)\n",
    "    # ax.set_ylim([-1-0.5,1.5])\n",
    "    ax.set_xlim([0*(cbatch*t_batch-4000), cbatch*t_batch])"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
